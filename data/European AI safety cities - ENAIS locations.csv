City,Name,,Description,Media link,Tags,Hub
Cracow,Cracow,We are about to start regular meetings in February/March (contact Mateusz Bagiński at AI Safety slack or wherever),,,,0
 Aarhus,Aarhus,Aarhus University has an AI safety interested Cognitive Science study and Apart Research has an office here. Write to zaki@apartresearch.com to hear more about what's happening in the city.,mailto:zaki@apartresearch.com,https://youtu.be/Nx5gIbTsHJM,ENAIS,0
Oxford,AI Safety Hub,"AI Safety Hub aims to support individuals who want to contribute to the safe development of AI, and does so primarily through supporting local AI safety groups across the globe. More information can be found on their website: aisafetyhub.org",,,,1
Groningen,AI Safety Initiative Groningen,"We have a lot of AI research and education going on in Groningen. Our mission is to empower and connect university students, academics, everyone - to shape a safe and responsible future of AI. We are running the AGISF course, hackathons, talks, and additional events. More information can be found on our website: https://www.aisig.org/.",aisig.org,mailto:info@aisig.org,ENAIS,1
 Amsterdam,Amsterdam,"The University of Amsterdam produces excellent AI research, including interpretability work, particularly in the ILLC and AMLab. However AIS is not widespread in the uni. One reinforcement learning researcher (Herke van Hoof) supervised two students in their safety-related master's thesis projects who then became full-time AIS researchers at the PhD student level, so there's at least some basic amount of openness toward safety work. In general, there is some amount of interest on AI Safety among university students and PhD students, and some university students read through the fundamentals program together. There is not AIS group yet. ",,,ENAIS,1
Budapest,BAIST (Budapest AI Safety Team),,https://www.budapestaisafety.org/,,ENAIS,1
Belgrade,Belgrade,"Several enthusiasts hold monthly meetings on AI Safety as part of EA Serbia. We plan to start AIS Fundamentals course in person, and are reaching out to universities around. We have some industry connections, may be able to get office space affordably for those who want to come and work remotely from Belgrade.",mailto:dusan.d.nesic@efektivnialtruizam.rs,,ENAIS,0
 Berlin,Berlin,"Irregular ""social"" discussion meetups for people to talk about AI alignment. Previously some hobbyist research, not anymore. Some research on interpretability at TUB, previously some research on safe reinforcement learning.",mailto:pranomestro@gmail.com,,ENAIS,1
 Brussels,Brussels,"Not a hub for technical AI safety research, but a hub for policy work. ",,,ENAIS,1
Cambridge,Cambridge,,https://www.cambridgeaisafety.org/,,,1
Copenhagen,Copenhagen,Apart Research and the Alignment Jams' headquarters are in Copenhagen. A weekly AI safety meetup happens at Bastard Café on Thursdays from 8PM. The AI Safety Reading Group and aisafety.com is also headquartered here with Søren Elverlin.,https://www.facebook.com/groups/266673130348543,,ENAIS,1
 Darmstadt,Darmstadt,,,,ENAIS,0
 Delft,Delft,"We are running AGISF and regularly organising hackathons. We are planning to scale up in the next months to become a bigger student organisation, attract more people and run cool projects. There is also one professor doing AI Safety (not with a focus on AGI tho) research here. (Website/social media will be set up soon. Until then you can contact us at: jan@eadelft.org)",,,ENAIS,1
 Trondheim,EA NTNU,"Trondheim has a thriving university EA group with members interested in AIS reading the AGISF corriculum. However, AIS has not yet penetrated the ML community at universities.",,,ENAIS,0
Bergen,EA UiB,"The university EA group in Bergen has organized reading groups on Human Compatible, and will likely continue with similar activities this year such as reading through the AGISF. Bergen has a couple of people interested in starting a separate group exclusively focusing on AIS.",,,ENAIS,0
 Oslo,EA UiO,The university EA group at UiO is planning to organizing an AGISF reading group this spring.,,,ENAIS,0
Eindhoven,Eindhoven AI Safety Team,"We're setting up an AI Safety Team in collaboration with Serpentine AI. There are several independant AIS researchers in Eindhoven, as well as some interested faculty. You can contact info@eaeindhoven.nl or join the group chat!",https://www.eaeindhoven.nl/ai-safety-team,,ENAIS,1
 Geneva,Geneva,,,,ENAIS,0
Tel Aviv,Israel,"ALTER Israel is working with several researchers, primarily focused on Vanessa Kosoy's Learning Theoretic Alignment, and supporting and connecting researchers in Israel with the broader safety community. We ran an AI Safety Israel conference in 2022, and are considering next steps and other opportunities. There is also a planned weekly AI-Safety coworking session at the EA Israel office. (Other locations in Israel are included as well.)",,,,1
 Karlsruhe,Karlsruhe,"I (Walter Laurito) am working on a project at SERI MATS right now, which I might continue in my city Karlsruhe afterwards. I'm also pursuing a PhD there and try to integrate AI Safety topics there, since I have some freedom in choosing what do work on. Apart from me, there are 5-6 people from the local EA community interested in AI Safety. Karlsruhe is famous for its university and great education in computer science in Germany. Furthermore, Karlsruhe has many different research labs... I think having talks, presentations and meetups about AI safety could be very valuable there... Once, I'm back from Berkeley, I will think about that more.",lauritowal@yahoo.com,,ENAIS,0
Lausanne,Lausanne,"Few research, but many interested students, some which do independent research. There is also LAIA, a student group started in 2022.",go.epfl.ch/laia,,ENAIS,1
London,London,"There exists a ""Connection"" shared slack channel ""london-ai-safety-hub"" mostly maintained by Maris Sala. Invite only, message Maris (maris@conjecture.dev) with your involvement in AI Safety to join.

SERI MATS currently have a coworking space in London.
Conjecture are based in London and may host visitors on direct invite.
Center on Long-term Risk is based in London.
Deepmind has a London office.
There also exist several uni groups, EA & Rationalish meetups",maris@conjecture.dev,,,1
Madrid,Madrid,,,,ENAIS,0
Magdeburg,Magdeburg,,,,ENAIS,0
Munich,Munich,"Couple of AIS discussion groups; high interest, but fragmented research. AIS not yet a prominent topic in universities",,,ENAIS,0
Munich,Munich,"There are currently two bi-weekly reading groups with slightly different focus
1. Advanced AI and Neural Networks with focus on Alignment (most recent papers and posts)
2. AI Safety fundamentals (Superintelligence)",,,,0
 Paris,Paris,There's a french AI safety community with enough members in Paris to have regular meetups,https://discord.gg/CDcRyyzqJ9,,ENAIS,0
 Prague,Prague,"- ACS research group
- Human-aligned Summerschool
- Prague Fall Season / FixedPoint co-working   -PIBBSS",,,ENAIS,1
Bratislava,Progressbar,"We're a former hackerspace (since 2010) now home to digital communities, among them Machine Learning and Effective Altruism.
We'll be delivering the AGI Safety programs to tech and non-tech folk, and generally advocate for AI Safety in policy and among the AI startups and corporates.",progressbar.sk,,,0
 Stockholm,Stockholm,"Direct work
Researchers:
- Anders Sandberg (part time in Stockholm region)
- Olle Häggström  (part time in Stockholm region)
- Allan Dafoe (part time in Stockholm region)
- Vincent Boulanin

People working with AI, with an interest in Safety
- Anton Osika
- Oliver Edholm
- Krisitan Rönn

Organizations with some relevance to AI Safety
- SIPRI
- Institutet för framtidsstudier

Movement building:
People
- Jonas Hallgren
- Chris Gerrby",,,ENAIS,0
Tallinn,Tallinn,,,,ENAIS,0
Tartu,Tartu,,,,ENAIS,0
 Tübingen,Tübingen,"Tübingen has a large cluster of AI institutes, including two Max-Planck Institutes and a large department at the university. The IMPRS-IS which is the joint program for all institutes has over 200 PhD students working on AI and related questions. According to statements by the organisers of the IMPRS-IS, Tübingen is the biggest AI location in Europe. There is a large and vibrant EA chapter in Tübingen that regularly has meetings with 20 or more people some of whom are focused on AI safety. Unfortunately, nobody in the faculty seems really interested about the kind of AI safety that tries to prevent catastrophic outcomes from misaligned AI. I (Marius) think there should be a presence of AI safety researchers there, but I'm also frustrated with the current faculty and thus intend to leave Tübingen in the near future. ",,,ENAIS,1
 Utrecht,Utrecht,"In Utrecht, both the technical and the governance track of the AGI Safety Fundamentals courses are being run. There is co-working, sometimes hackathons, a paper reading group. You can contact mailvanteun@gmail.com for more information, or apply on the website! ",https://eautrecht.nl/aisafety,https://eautrecht.nl/aisafety,ENAIS,0
 Vienna,VAIA,"In Vienna, there is VAIA, the Vienna AI Alignment Group, a recently founded network of professionals working on AI alignment. The group includes academic researchers, startup staff, as well as independent researchers.",https://github.com/ViennaAI/info,,ENAIS,0
 Zurich,ZAIA,"Zürich AI Alignment group (ZAIA): (see website)
1) AGI Safety Fundamentals Course
2) Reading group discussing recent AI safety research
3) Collaboration on research projects

ETH Zürich near-term AI safety research:
1) Safe Artificial Intelligence
2) Computer Security and Privacy Group 
3) Learning & Adaptive Systems Group  

OpenPhil funded researchers:
1) Prof. Dr. Florian Tramèr (formerly OpenPhil)
2) Cynthia Chen (PhD student)
3) Zhijing Jin (PhD student)

Other researchers:
1) Lennart Heim (GovAI) 
2) Jérémy Scheurer (FAR AI)
3) Johannes Gasteiger (Google Research)",https://www.zurich-ai-alignment.com/ ,,ENAIS,1
Helsinki,Helsinki,"Direct work: 
Researchers: 
- Anna Katariina Wisakanto (part time in Helsinki region)",,,ENAIS,0